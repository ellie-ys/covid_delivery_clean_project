# (클린한끼)
- 코로나로 인한 배달서비스 급증에 따른 소비자 민원 조사 및 위생상태 불량 적발 건수 데이터 분석과 이러한 사용자들의 불만해결을 위한 지역별 위생 가게 정보 제공
- [클린한끼 사이트 바로가기](https://kdt-vm-0202011.koreacentral.cloudapp.azure.com/)

## 프로젝트 아키텍처 

![image](https://user-images.githubusercontent.com/76929823/137636476-de8b0ccd-67cb-4ada-abf0-91760cdf315e.png)

🗓 **프로젝트 일정**

- 프로젝트 기간 : 2021.9.27(월) ~ 2021.10.15(금)

![image](https://user-images.githubusercontent.com/76929823/137832730-7af13496-6cf9-49e8-8df4-887bf73d74b1.png)


## 1. 프로젝트 소개

**어떠한 데이터셋와 도구 및 기술을 사용했는지에 대한 설명과 엔드유저에게 보이는 웹서비스에 대한 소개**
- 사용하려는 데이터(제안된 데이터 중 하나 또는 선택한 다른 데이터 세트)를 명시, 이에 대한 설명
  - [전국 인허가 데이터 행정안전부_일반음식점(수시)20210731](https://www.data.go.kr/data/15045016/fileData.do)
  - [행정안전부휴게음식점(수시)_20210731](https://www.localdata.go.kr/data/dataView.do)
  - [식품안전나라 '식품접객업소 위생등급 지정현황' 식품의약품안전처](https://www.foodsafetykorea.go.kr/apiMain.do)
  - [통계청 온라인 쇼핑 거래액 ( 음식 서비스)](http://kostat.go.kr/understand/info/info_lge/1/detail_lang.action?bmode=detail_lang&cd=SL4420)

- 기술 스택 (python, flask, javascript, react, MySQL 등)
- 사용된 라이브러리 (pandas, numpy, matplotlib, wordcloud, chart.js 등)
- 웹서비스에 대한 자세한 개요 (코로나로 인한 배달서비스 급증에 따른 소비자 민원 조사 및 위생상태 불량 적발 건수 데이터 분석과 이러한 사용자들의 불만해결을 위한 지역별 위생 가게 정보 제공)

## 2. 프로젝트 목표

**데이터 분석 결과로 도출되는 인사이트와 웹서비스의 해결과제에 대한 논의 (50자 이상)**
- 프로젝트 아이디어 동기
  - 데이터 분석 결과 코로나로 인해 배달음식이 급증했다는 인사이트를 얻고, 배달음식이 조리상태를 확인할 수 없어 위생상태에 대한 불만이 많다는 사실을 알게 되었습니다. 그래서 이러한 소비자 불만을 해결하기 위한 정보제공 서비스를 개발하고자 하였습니다.

## 3. 프로젝트 기능 설명

**웹서비스의 유용성, 편의성 및 시각화의 실용성에 대한 설명**
  - 주요 기능 (주된 활용성) 및 서브 기능
    - 정보검색 기능
      - 배달 관련 데이터 정보 제공
      - 전국 위생가게 현황 및 등급 시각화
      - 식약처 위생인증 정보 확인
      - 메뉴 추천 추천 게임 ( 음식 마방진, 음식16강)
  
  - 프로젝트만의 차별점, 기대 효과
    * 통계적 기법(정규화)을 이용한 데이터 전처리를 바탕으로 정확한 정보 제공

## 4. 프로젝트 구성도 및 기능 설명
  - [클린한끼](https://whimsical.com/v3-3ctRi38AoRBshnap5YwmxJ)
### To-Do List

* [x] 지역별 위생등급별 가게수 확인 기능
* [x] 위생가게 수에 따른 지도 색표시 기능
* [x] 위생가게 수치를 절대값, 상대값 전환 기능
* [x] 프로젝트 소개 페이지 그래프 시각화기능
  * [x] 코로나 전후 배달대행 건수 비교 막대 그래프 
  * [x] 배달음식 민원 비율 그래프
  * [x] 코로나 이후 위생 상태 불량 적발 건수 증가 그래프
* [x] 위생가게 정보 검색 기능
  * [x] 가게이름별 검색
  * [x] 지역별 검색
  * [x] 업태(ex.한식, 중식, 양식, 카페,디저트)별 검색
  * [x] 사용자 위치 기반으로 가까운 가게 우선순위로 데이터 리스트 출력 기능
  * [x] 프랜차이즈를 제외한 일반가게만 보기 기능
  * [ ] ~~가게별 네이버 별점, 가게 영업시간 정보 제공 기능~~
* [x] 먹고 싶은 메뉴 고르기 게임 기능
  * [x] 메뉴 지뢰 찾기
  * [x] 메뉴 월드컵 16강
   * [X] 다시 하기 기능 
   * [ ] ~~공유하기 버튼~~
* [ ] ~~먹고 싶은 메뉴와 위생가게 연결기능~~

## 5. 프로젝트 팀원 역할 분담
| 이름 | 담당 업무 |
| ------ | ------ |
| 강경모 | 팀장/프론트엔드 개발 |
| 고예림 | 프론트엔드 개발 |
| 김기원 | 기획/데이터분석/백엔드 개발|
| 민경준 | 프론트엔드 개발/백엔드 개발/데이터분석 |
| 최윤성| 기획/데이터분석/백엔드 개발 |

**멤버별 responsibility**

1. 팀장 

- 기획 단계: 구체적인 설계와 지표에 따른 프로젝트 제안서 작성
- 개발 단계: 팀원간의 일정 등 조율 + 프론트 or 백엔드 개발
- 수정 단계: 기획, 스크럼 진행, 코치님 피드백 반영해서 수정, 발표 준비

2. 프론트엔드 

- 기획 단계: 큰 주제에서 문제 해결 아이디어 도출, 데이터 수집, 와이어프레임 작성
- 개발 단계: 와이어프레임을 기반으로 구현, 데이터 처리 및 시각화 담당, UI 디자인 완성
- 수정 단계: 피드백 반영해서 프론트 디자인 수정

 3. 백엔드 & 데이터 담당& 기획 

- 기획 단계: 기획 데이터 분석을 통해 해결하고자 하는 문제를 정의
- 개발 단계: 웹 서버 사용자가 직접 백엔드에 저장할수 있는 기능 구현, 데이터 베이스 구축 및 API 활용, 데이터 분석 개념 총동원하기
- 수정 단계: 코치님 피드백 반영해서 분석/ 시각화 방식 수정

## 6. 버전
  - 프로젝트의 버전 기입
    - V1 - 대시보드형태의 데이터 시각화 정보제공
    - V2 - 스토리텔링 형태의 데이터 시각화 정보제공
    - V3 - 스토리텔링 형태의 데이터 시각화 정보 및 거리기반 위생 가게 정보 제공 및 사용자에게 재미 요소인 메뉴 고르기 게임 

## 7. FAQ
  - 자주 받는 질문 정리

## 8. 배운점
- 기술
  - 백엔드 
    - 가볍고 심플한 서버를 만들기 위해 web Framework인 Flask를 이용했으며, Blueprint라는 python 라이브러리를 이용하여 app.py파일이 아닌 main_api.py파일에 api를 따로 구성했습니다.
    - server와 client 폴더를 구분하고, api url이 여러개거나 더 큰 프로젝트일 경우에 디렉토리 구조를 신경쓰는 것 외에도 효율적인 개발을 위한 디자인 패턴에도 관심이 생겼습니다.
    - api를 이용해 데이터를 요청할 때 요청한 파라미터가 노출되지않게 하기위해 GET이 아닌 POST method(http request)를 사용하였습니다. 
    - Postman을 활용하여, 데이터 요청이 가능한지 서버 api가 제대로 작동하는지 확인할 수 있습니다. 
    - 서버와 클라이언트 http 통신이 가능하도록 javascript 라이브러리인 axios를 사용해 Client가 데이터를 요청해 받아올 수 있었습니다.

    - 데이터 베이스는 mysql을 사용하여, 분석한 데이터를 vscode mysql로 보내고, .sql파일을 export해 azure vm에 있는 mysql에 넣기도 했습니다.
      
    - WAS(web application server)와 Web server에 대해서도 알 수 있었습니다. azure VM에 접속해 web server인 nginx를 이용한 배포를 경험해보았습니다.
    - 동적인 react를 정적으로 만들기 위해 build하였고 nginx 설정 default.conf파일에서 react를 build한 build 파일 위치와, backgroud 실행을 한 flask의 api url를 입력하는 과정을 통해 배포할 수 있었습니다. 더 나아가 계속해서 서비스를 이어나가는데 효율성을 위해 배포와 빌드에 들어가는 시간과 비용이 줄어드는 CI/CD 파이프라인을 적용해보고 싶다는 생각이 들었습니다.

    - server에서는 requirement.txt, client에서는 package.json를 통해 dependency 모듈을 관리해보았습니다. 
    - gitlab을 이용한 팀프로젝트를 하면서, git message.txt를 이용해 같은 양식으로 commit을 했고, 다시 확인했을 때 commit 메세지만 봐도 어떤 수정사항이 있었는지, 해쉬번호는 어떤 것인지 확인할 수 있어 재미있었습니다. 
   
    - 최종 발표 전날 잘못 push를 했고 그 이후에 또 다른 팀원이 commit과 merge를 하는 이슈가 있어 이전 commit으로 되돌리고 마스터 브랜치로 강제 푸쉬를 하는 작업이 필요하다 생각했습니다. 혼자서 했던 git은 잘 안되면 삭제하고 폴더를 새로 만들기도 했었는데. 함께한 작업이라 무조건 해결해야한다고 생각했지만, 마스터 브랜치는 보호되어있어 강제 푸쉬는 불가능했습니다.
    - 밤 12시가 넘은 상황이지만 기꺼이 함께해주는 고마운 팀원과 화면공유를 통해 함께 검색하며 해결할 수 있었습니다. 실수였지만 마스터 브랜치 보호를 풀고, 예전 상태로 되돌려서 다시 push하고 다시 마스터 브랜치를 보호 설정하는 등의 작업을 통해 정말 git과 더 많이 친해질 수 있었습니다.
    
   
  - 기획
    - 애자일 방법론을 이용했습니다.
    - 어제 한일, 오늘 할일, 이슈를 회의록으로 작성하였고 office hour에 질문하고 싶은 내용을 기록하는 등 office hour를 알차게 보내기 위해 노력했습니다. 
    - wire frame을 만들어 유저관점에서도 고민해보았고 우리의 질문을 토대로 해주신 코치의 피드백도 반영해 빠르게 와이어프레임을 여러차례 수정해 개발 공백이 없도록 했습니다.
    - 목표를 세분화하여 시간을 정하는 등의 일정관리를 통해 완성도 높은 프로젝트를 할 수 있었습니다.
    - 3주동안 매일 오전 10시 스크럼을 하였고 저녁에도 회고를 하는 등 자발적으로 할 일을 공유하고 자주 만나 소통하며 프론트앤드, 백엔드 모든 팀원이 점차 같은 방향을 보게되었습니다.

  - 데이터 분석
    - jupyter notebook을 이용하여 분석을 했습니다.
    - 코로나 이후로 위생에 대한 인식이 높아졌지만 음식점 위생에 관련된 민원은 늘어나며, 음식점의 위생관리는 따라가지 못하고 있는 실정입니다. 이러한 데이터를 수집하기 위해 우리 서비스가 만들어지게 된 근거를 그래프로 만들어 제시했습니다.
    - 또 이러한 문제를 해결하기 위해 위생관리가 잘 되어있는 식약처 위생 인증을 받은 음식점을 보여주는 프로젝트를 기획했고, 이와 관련된 모든 데이터를 수집했습니다.
    - 식약처 위생 인증을 받은 데이터는 대략 27100개로 이 만큼의 데이터로 서비스를 기획하는 건 고민스러운 일이었습니다. 그래서 서울시 공공데이터나 모범음식점이나 착한 가게 음식점 등의 데이터도 이용할 수 있는 방법을 모색했지만, 주소와 데이터가 맞지 않는 등 데이터의 정확성이 떨어졌으며 폐업이 된 곳, 위생 인증 유효기간이 지난 곳, 위생음식점이라는 주제와 맞지 않는 곳, 결국은 식품의약품 안전처의 공공데이터 api를 가져와 사용하는 게 가장 데이터의 정확도가 높다는 것을 알게 되었습니다.
    - 또한 처음 프로젝트 방향성은 메뉴를 추천하는 간단한 게임을 통해 메뉴가 결정되면, 그 메뉴에 관련된 위생 인증 가게를 보여주는 방향이었는데, 분석을 해보니 위생 인증 식당이 프랜차이즈나 카페 위주였으므로 메뉴를 추천해도 그 메뉴에 관련된 지역의 음식점이 없을 가능성이 높다는 이슈가 있어 그 지역의 위생 가게 리스트를 제공하기로 했습니다.
    - 위생 인증을 받은 식당은 프랜차이즈, 카페 비율이 높았기에 위생 인증 식당 중에서도 프랜차이즈와 일반 식당을 구분해 보여줄 필요도 있다고 생각해 프랜차이즈에 대한 기준을 정하기도 했습니다.
    - 전국 지도에 여러 수치화한 데이터를 보여주고 싶지만, 단순하게 위생 인증을 받은 식당 숫자를 보여주는 것보다 그 지역의 가게 수 대비 위생 인증 식당을 보여주기 위해 전국 식품접객업소에 관한 데이터 (87만 개)도 가공해야 했고, 그 87만 개의 데이터에는 업종분류표와 x, y 좌표 동-주소 등의 정보가 있어, 위생 인증 식당 데이터에 유저 관점에서 필요한 정보를 사용할 수 있었습니다.
    - 또한 프랜차이즈와 아닌 업소로 구분을 하며 위생 인증을 받은 업소 중 프랜차이즈 비율이 높다는 편견을 줄 수도 있어서 그 지역 전체 프랜차이즈 가게 대비 위생 인증을 받은 프랜차이즈를 보여주는 등의 인사이트도 제공하게 되었습니다.

  - 기술 이외 배운점
    - 커뮤니케이션과 팀웍에 대한 중요성을 배울 수 있었습니다.
    - 방향이 흔들릴 때마다 고민도 많이 하고 어려운 적도 있었지만, 팀원들과 서로 호흡을 맞추며 함께 성장하는 즐거움을 느낄 수 있었습니다.
    - 영어이름을 부르는 등 수평적인 팀 문화를 만들어가며 각자 맡은 바 최선을 다해 노력하는 분위기에서 혼자서는 할 수 없었던 많은 걸 배울 수 있었습니다.  
    - 최종발표 땐 '주제가 적절했다', '팀웍이 대단했다', 그리고 '정말로 스타트업와 같은 분위기였다' 는 담당 코치님의 피드백도 받을 수 있어 뿌듯했습니다. 
